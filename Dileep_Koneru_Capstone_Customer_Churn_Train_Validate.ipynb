{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Set the rc params for axes, xtick, and ytick\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "#Finally, we will import warnings and ensure that the non-essential warnings are ignored\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "\n",
    "#Load the dataset\n",
    "churn = pd.read_csv('churn_train.csv')\n",
    "\n",
    "#Drop basic attributes like State, Area code\n",
    "churn = churn.drop(['State','Area code'], axis=1)\n",
    "\n",
    "'''\n",
    "for column in churn.select_dtypes(include=[\"object\"]).columns:\n",
    "    if column != \"Churn\":\n",
    "        display(pd.crosstab(index=churn[column], columns=churn[\"Churn\"], normalize=\"columns\"))\n",
    "\n",
    "for column in churn.select_dtypes(exclude=[\"object\"]).columns:\n",
    "    print(column)\n",
    "    hist = churn[[column, \"Churn\"]].hist(by=\"Churn\", bins=30)\n",
    "    plt.show()\n",
    "  \n",
    "display(churn.corr(numeric_only=True))\n",
    "pd.plotting.scatter_matrix(churn, figsize=(12, 12))\n",
    "plt.show()\n",
    "\n",
    "df['color'] = df['color'].astype('category')\n",
    "df['color_encoded'] = df['color'].cat.codes\n",
    "'''\n",
    "\n",
    "#Let us convert categorical fields into numerics - Voice mail plan, International plan, Churn\n",
    "churn['Voicemail_plan_upd'] = churn['Voice mail plan'].astype('category').cat.codes\n",
    "churn['International_plan_upd'] = churn['International plan'].astype('category').cat.codes\n",
    "churn['Churn_upd'] = churn['Churn'].astype('category').cat.codes\n",
    "\n",
    "# Run the Correlation matrix of each feature against the label and Identify what attributes are unnecessary\n",
    "#print(churn.corr())\n",
    "\n",
    "#Going by the Correlation matrix, Total day charge, Total eve charge, Total night charge are just repetitive. Hence dropping them off\n",
    "churn = churn.drop(['Voice mail plan','International plan','Churn','Total day charge','Total eve charge','Total night charge'],axis=1)\n",
    "\n",
    "'''\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "l1=churn['Voice mail plan']\n",
    "l2=churn['Churn']\n",
    "\n",
    "corr, _ = pearsonr(l1, l2)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "'''\n",
    "\n",
    "#Checking the data scatter, nulls & other metrics of data\n",
    "#churn.describe()\n",
    "\n",
    "# Store the labels in a variable\n",
    "churn_label = churn['Churn_upd'].copy()\n",
    "\n",
    "#Drop Churn_upd from dataframe\n",
    "churn = churn.drop(['Churn_upd'],axis=1)\n",
    "\n",
    "#Split the data into Train, Validation & Test data sets\n",
    "#First split the data into Train & Test. Next split the Train data into Train & Validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(churn, churn_label, test_size=0.4, random_state=42)\n",
    "\n",
    "#Start evaluating different ML models for best performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8375\n",
      "Logistic Regression AUC Score is 0.7168666294642857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Start with Logistic Regression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "lr_y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "lr_accuracy = accuracy_score(y_test, lr_y_pred)\n",
    "print(\"Accuracy:\", lr_accuracy)\n",
    "\n",
    "#AUC Score for Logistic Regression\n",
    "#First, we need to use predic_prob method\n",
    "\n",
    "lr_y_pred_prob = lr.predict_proba(X_test)\n",
    "\n",
    "lr_auc_score = roc_auc_score(y_test, lr_y_pred_prob[:,1])\n",
    "print(\"Logistic Regression AUC Score is\",lr_auc_score)\n",
    "\n",
    "#Steps to save the LR model\n",
    "#lr_model = pickle.dumps(lr)\n",
    "\n",
    "lr_model_pkl_file = \"lr_model_pkl_file.pkl\"  \n",
    "\n",
    "with open(lr_model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(lr, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Accuracy: 0.84\n",
      "SGD Predict AUC Score is 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/lib/python3.6/site-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Using SGD Classifier algorithm\n",
    "sgd_clf = SGDClassifier(random_state=42, max_iter=10)\n",
    "\n",
    "#Train the classifier\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the Test data\n",
    "y_pred_sgd = sgd_clf.predict(X_test.values)\n",
    "#y_pred_sgd = sgd_clf.predict([X_test.iloc[251]])\n",
    "\n",
    "#print(y_pred_sgd)\n",
    "\n",
    "#Predict Probability\n",
    "#y_pred_prob_sgd = sgd_clf.predict_proba(X_test.values)\n",
    "\n",
    "# Evaluate the model\n",
    "sgd_accuracy = accuracy_score(y_test, y_pred_sgd)\n",
    "print(\"SGD Accuracy:\", sgd_accuracy)\n",
    "\n",
    "sgd_auc_score = roc_auc_score(y_test, y_pred_sgd)\n",
    "print(\"SGD Predict AUC Score is\",sgd_auc_score)\n",
    "\n",
    "#sgd_auc_score_prob = roc_auc_score(y_test, y_pred_prob_sgd[:,1])\n",
    "#print(\"SGD Predict Probability AUC Score is\",sgd_auc_score_prob)\n",
    "\n",
    "#steps to Save the model\n",
    "sgd_model_pkl_file = \"sgd_model_pkl_file.pkl\"  \n",
    "\n",
    "with open(sgd_model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(sgd_clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy: 0.85875\n",
      "DT Predict AUC Score is 0.5617559523809523\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Now let's train the DecisionTreeRegressor\n",
    "dt_clf = DecisionTreeClassifier(random_state=42,max_depth=3)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "#Now let's predict using our model using the predict method\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "\n",
    "#cv_score = cross_val_score(dt_clf, X_train, y_train, cv=10)\n",
    "\n",
    "#print(cv_score)\n",
    "\n",
    "# Evaluate the model\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"DT Accuracy:\", dt_accuracy)\n",
    "\n",
    "dt_auc_score = roc_auc_score(y_test, y_pred_dt)\n",
    "print(\"DT Predict AUC Score is\",dt_auc_score)\n",
    "\n",
    "\n",
    "#steps to Save the model\n",
    "dt_model_pkl_file = \"dt_model_pkl_file.pkl\"  \n",
    "\n",
    "with open(dt_model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(dt_clf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 0.91\n",
      "RF Predict AUC Score is 0.7219122023809523\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Now let's train the DecisionTreeRegressor\n",
    "rf_clf = RandomForestClassifier(random_state=42, max_depth=10)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "#Now let's predict using our model using the predict method\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"RF Accuracy:\", rf_accuracy)\n",
    "\n",
    "rf_auc_score = roc_auc_score(y_test, y_pred_rf)\n",
    "print(\"RF Predict AUC Score is\",rf_auc_score)\n",
    "\n",
    "#Steps to save the model\n",
    "rf_model_pkl_file = \"rf_model_pkl_file.pkl\"  \n",
    "\n",
    "with open(rf_model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(rf_clf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.847726\n",
      "Will train until validation_0-auc hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-auc:0.863758\n",
      "[2]\tvalidation_0-auc:0.868908\n",
      "[3]\tvalidation_0-auc:0.870582\n",
      "[4]\tvalidation_0-auc:0.872332\n",
      "[5]\tvalidation_0-auc:0.876529\n",
      "[6]\tvalidation_0-auc:0.879668\n",
      "[7]\tvalidation_0-auc:0.880226\n",
      "[8]\tvalidation_0-auc:0.878738\n",
      "[9]\tvalidation_0-auc:0.878476\n",
      "[10]\tvalidation_0-auc:0.882394\n",
      "[11]\tvalidation_0-auc:0.88344\n",
      "[12]\tvalidation_0-auc:0.883859\n",
      "[13]\tvalidation_0-auc:0.887381\n",
      "[14]\tvalidation_0-auc:0.885905\n",
      "[15]\tvalidation_0-auc:0.893125\n",
      "[16]\tvalidation_0-auc:0.893683\n",
      "[17]\tvalidation_0-auc:0.894432\n",
      "[18]\tvalidation_0-auc:0.894816\n",
      "[19]\tvalidation_0-auc:0.894525\n",
      "[20]\tvalidation_0-auc:0.903378\n",
      "[21]\tvalidation_0-auc:0.903367\n",
      "[22]\tvalidation_0-auc:0.904053\n",
      "[23]\tvalidation_0-auc:0.904925\n",
      "[24]\tvalidation_0-auc:0.904431\n",
      "[25]\tvalidation_0-auc:0.905611\n",
      "[26]\tvalidation_0-auc:0.910987\n",
      "[27]\tvalidation_0-auc:0.910238\n",
      "[28]\tvalidation_0-auc:0.909575\n",
      "[29]\tvalidation_0-auc:0.908035\n",
      "[30]\tvalidation_0-auc:0.908662\n",
      "[31]\tvalidation_0-auc:0.905273\n",
      "Stopping. Best iteration:\n",
      "[26]\tvalidation_0-auc:0.910987\n",
      "\n",
      "XGB Accuracy is 0.9175\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_pretrain_clf = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',  # For Binary-class classification\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    n_estimators=50,\n",
    "    eval_metric=\"auc\"\n",
    "       \n",
    ")\n",
    "\n",
    "#eval_metric=[\"auc\", \"error\", \"error@0.6\"]\n",
    "\n",
    "xgb_pretrain_clf.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_test, y_test)])\n",
    "\n",
    "y_pred = xgb_pretrain_clf.predict(X_test)\n",
    "\n",
    "xgb_pretrain_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"XGB Accuracy is\", xgb_pretrain_accuracy)\n",
    "\n",
    "#Steps to save the model\n",
    "xgb_model_PreTrain_pkl_file = \"xgb_model_PreTrain_pkl_file.pkl\"  \n",
    "\n",
    "with open(xgb_model_PreTrain_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(xgb_pretrain_clf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of hyperparameters:  {'learning_rate': 0.1, 'max_depth': 5, 'subsample': 0.5}\n",
      "Best score:  0.9516213389121339\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "#Since XGBoost's base model performance was better than the rest, tune the XGB model to find the best set of hyperparameters\n",
    "#Find the best set of hyperparameters for XGBoost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.5, 0.7, 1]\n",
    "    }\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_hyper_clf = xgb.XGBClassifier(objective='binary:logistic',  # For Binary-class classification\n",
    "    n_estimators=50, eval_metric=\"auc\")\n",
    "\n",
    "#eval_metric=[\"auc\", \"error\", \"error@0.6\"]\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_hyper_clf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Accuracy is 0.94125\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "#Apply the best hyperparameters from above and use it for train & predict\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(objective='binary:logistic',  # For Binary-class classification\n",
    "    learning_rate= 0.1, max_depth =5, subsample=0.5, n_estimators=50, eval_metric=\"auc\")\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the data for X_test\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"XGB Accuracy is\", xgb_accuracy)\n",
    "\n",
    "#Steps to save the model\n",
    "xgb_model_pkl_file = \"xgb_model_pkl_file.pkl\"  \n",
    "\n",
    "with open(xgb_model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(xgb_clf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
